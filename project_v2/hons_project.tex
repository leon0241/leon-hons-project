\documentclass[logo,bsc,singlespacing,parskip,online]{infthesis}
\usepackage{ugcheck}


\usepackage[final, nopatch=footnote]{microtype} % recommended, but you can remove if it causes problems
\usepackage[round]{natbib} % recommended for citations

\usepackage{preamble}


\begin{document}
\begin{preliminary}

\title{Honours Project}

\author{Leon Lee}
\course{Computer Science and Mathematics}
\project{4th Year Project Report}
\date{\today}

\abstract{
This skeleton demonstrates how to use the \texttt{infthesis} style for
undergraduate dissertations in the School of Informatics. It also emphasises the
page limit, and that you must not deviate from the required style.
The file \texttt{skeleton.tex} generates this document and should be used as a
starting point for your thesis. Replace this abstract text with a concise
summary of your report.
}

\maketitle

\newenvironment{ethics}
   {\begin{frontenv}{Research Ethics Approval}{\LARGE}}
   {\end{frontenv}\newpage}

\begin{ethics}
This project was planned in accordance with the Informatics Research
Ethics policy. It did not involve any aspects that required approval
from the Informatics Research Ethics committee.

\standarddeclaration
\end{ethics}


\begin{acknowledgements}
Any acknowledgements go here.
\end{acknowledgements}


\tableofcontents
\end{preliminary}


\chapter{Introduction}

\chapter{Background}

\section{Process Algebra}
With the growing complexities of software and systems of the world, it is key to have methods of modelling more complex systems to get a better understanding of the underlying behaviour behind processes. Efforts have been made in sequential programming as early as the 1930s with Turing Machines, and the $\lambda$-calculus. Systems in real life are rarely sequential however, and usually involve multiple processes acting simultaneously, sometimes even synchronising to interact with each other to perform tasks. These tasks that involve modelling multiple processes at once are referred to as a \textit{Concurrent System}. It is clear to see that brute forcing solutions to these problems are significantly harder than a sequential system - the processing time will grow exponentially as the number of processes increase, and modelling a system like a colony of ants is near impossible. Therefore, we will need some way to formalise these Concurrent Systems.

Concurrency has been studied in many different ways, though with the earliest  the 1960s with some notable models being Petri nets, or the Actor Model. Process Algebras are one such method of modelling a Concurrent System, where the process is modelled in such a way that it is akin to the Universal Algebras of mathematics - in which operations are defined in an axiomatic approach to create a structurally sound way of defining concurrent systems. \citep{baetenBriefHistoryProcess2005} It is easily possible to model simple systems as a flow chart or diagram as you will be able to see throughout this paper, but a formal approach like process algebras will make way for modelling more complex systems, and lays the groundwork to provide a solid foundation to prove and base claims for such systems.

A simple example in action is a process algebra where we only consider the alternative composition operator $+$, where applied to a process $a + b$ means ``Choose $a$, or choose $b$''. Process algebras can typically be modelled in a \textit{Process Graph}, which are diagrams that employ ``states'', and ``actions'' to show the traces, or paths, that a process can take. In this case, the process $a + b$ can be modelled in the following way:

% https://q.uiver.app/#q=WzAsNixbMSwxLCJcXGNpcmMiXSxbMCwyLCJcXGNpcmMiXSxbMiwyLCJcXGNpcmMiXSxbMiw1XSxbMSw1LCJcXGJ1bGxldCJdLFsxLDBdLFswLDEsImEiLDJdLFswLDIsImIiXSxbMyw0XSxbNSwwXV0=
\[\begin{tikzcd}[cramped,column sep=small]
	& {} \\
	& \circ \\
	\circ && \circ \\
	\arrow[from=1-2, to=2-2]
	\arrow["a"', from=2-2, to=3-1]
	\arrow["b", from=2-2, to=3-3]
\end{tikzcd}\]

Where the graph begins at the top into the first node, and then can either progress to the left node via the action $a$, or the right node via the action $b$. $a$ and $b$ are the actions, e.g. ``eat'' and ``drink'', while the nodes are the states, e.g. ``apple'' and ``water''

The axioms of the $+$ operator of BPA are as follows:
\begin{itemize}
    \item \textbf{Commutativity}: $a + b$
    \item \textbf{Associativity}: $(a + b) + c = a + (b + c)$
    \item \textbf{Idempotency}: $a + a = a$
\end{itemize}
Comparable to the operation axioms of a Group or Ring in Mathematics, every other operation in a process algebra is constructed similarly. In practice, most process algebras will have some form of alternative composition, but this is a very simplified example and the developed process algebras that exist are designed to handle a lot more complex situations such as unobservable actions, commonly referred to as $\tau$-actions, recursion, which lets a process repeat itself or other processes, and deadlock, which is a state where no desirable outcomes can be reached.

There are many process algebras that exist, the most famous and seminal being CSP \citep{brookesTheoryCommunicatingSequential1984}, CCS \citep{milnerCalculusCommunicatingSystems1980}, and ACP \citep{bergstraProcessAlgebraSynchronous1984}, \citep{bergstraACPtUniversalAxiom1989}, with some other popular calculi being the $\pi$-calculus and its various extensions  \citep{MILNER19921}, \citep{parrowFusionCalculusExpressiveness1998}, \citep{abadiCalculusCryptographicProtocols1999} which have been used to varying degrees in fields like Biology, Business, and Cryptography, or the Ambient Calculus \citep{cardelliMobileAmbients1998} which has been used to model mobile devices.

\section{Encodings of Process Algebra}

With the growing number of process algebras, one might begin to ask if there is a way of comparing different process algebra to each other to find the single best one, as a parallel to Turing Machines and the Church-Turing thesis. However, the wide range of applications that different process algebra are used for makes that rather impractical, and the goal of unifying all process algebra into a single theory seems further and further away as more process algebras for even more specified tasks get created.

A more reasonable approach is to compare different process algebras and their expressiveness, two main relevant methods being \textit{absolute} and \textit{relative} expressiveness.\citep{parrowExpressivenessProcessAlgebras2008} Absolute expressiveness is the idea of comparing a specific process algebra to a question and seeing if it can solve the problem - e.g. if a process algebra is Turing Complete. However, this merely biparts different algebra - the process algebra that are able to solve a specified problem, and the ones who aren't \citep{gorlaUnifiedApproachEncodability2010}. Therefore, the question of relative expressiveness - i.e. how one language compares to another is a lot more useful in terms of categorising different process algebras by expressiveness.

A well studied way of comparing expressiveness is through an ``encoding'', and whether an algebra can be translated from one to another, but not vice versa \citep{petersComparingProcessCalculi2019}. The general notion of an encoding is not defined by clear boundaries, and the criterion for a valid encoding may vary from language to language, but work has been made to try and generalise the notion of a ``valid'' encoding \citep{gorlaUnifiedApproachEncodability2010}, \citep{DBLP:conf/fossacs/Glabbeek18}.

\section{CSP}
CSP (Communicating Sequential Processes) \citep{brookesTheoryCommunicatingSequential1984} is a Process Algebra developed by Tony Hoare based on the idea of message passing via communications. It was developed in the 1980s and was one of the first of its kind, alongside CCS by Milner. CSP uses the idea of action prefixing which is where operators are of the syntax $a \to P$, where $a$ is an event and $P$ is a process. 

As taken from \citet{vanglabbeekBranchingTimeModel2017}, the syntax of CSP can be expressed as follows
\begin{align*}
   P, Q ::= &\mathrm{STOP} \mid \mathrm{div} \mid a\to P \mid P \sqcap Q \mid P \detcomp Q \mid P \triangleleft Q \mid \\
	&P | |_{A} Q \mid P \backslash A \mid f(P) \mid P \triangle Q \mid P \theta_{A} Q \mid p \mid \mu p.P
\end{align*}
where the operators are: \textit{inaction}, \textit{divergence}, \textit{action prefixing}, \textit{internal choice}, \textit{external choice}, \textit{sliding choice}, \textit{parallel composition}, \textit{concealment}, \textit{renaming}, \textit{interrupt}, and \textit{throw}.


\section{ACP}
ACP (Algebra of Communicating Processes) is a Process Algebra developed by Jan Bergstra and Jan Willem Klop \citep{bergstraProcessAlgebraSynchronous1984}. Compared to CSP, ACP is built up with an axiomatic approach in mind which does away with the idea of action prefixing and instead can allow for unguarded operations. ACP$_{\tau}$ \citep{bergstraACPtUniversalAxiom1989} is an extension of ACP that includes an extra action $\tau$ which is used to represent actions that are unobservable, or changeable, from a human perspective.

The grammar of ACP$_{\tau}$ as taken from \citep{bergstraACPtUniversalAxiom1989} is defined as such:
\begin{align*}
   P, Q ::= a \mid \delta \mid E + F \mid E . F \mid E | | F \mid E \underline{| | \,} F \mid E | F \mid \partial_{H}(E) \mid \tau_{I}
\end{align*}
where the operators are: \textit{action}, \textit{deadlock}, \textit{alternative composition}, \textit{sequential composition}, \textit{merge}, \textit{left merge}, \textit{communication merge}, \textit{encapsulation}, \textit{abstraction}

\chapter{A formal definition of CSP and ACP}

From [EXPRESSIVENESS], we represent a language $\mathscr{L}$ as a pair $(\mathbb{T}, \oper)$, where $\mathbb{T}$ is a set of valid expressions in $\mathscr{L}$, and $\oper$ is a mapping $\oper : \mathbb{T} \to \mathscr{D}$ from $\mathbb{T}$ to a set of meanings $\mathscr{D}$. We also define $A \subseteq \mathbb{T}$, where $A$ is the set of actions


Somethin something we are trying to gain an expressiveness result by translating CSP to ACP. A result of a valid translation would therefore show that CSP is \textit{at least as expressive} as ACP.

\chapter{A Translation of CSP to ACP}

As stated above, the grammar of CSP consists of the operations:

\begin{align*}
   P, Q ::= &\mathrm{STOP} \mid \mathrm{div} \mid a\to P \mid P \sqcap Q \mid P \detcomp Q \mid P \triangleleft Q \mid \\
	&P | |_{A} Q \mid P \backslash A \mid f(P) \mid P \triangle Q \mid P \theta_{A} Q \mid p \mid 
\end{align*}
%\mu p.P
where the operators are: \textit{inaction}, \textit{divergence}, \textit{action prefixing}, \textit{internal choice}, \textit{external choice}, \textit{sliding choice}, \textit{parallel composition}, \textit{concealment}, \textit{renaming}, \textit{interrupt}, and \textit{throw}.

These can also be represented in the following GSOS table

[INSERT TABLE HERE]

As they are in GSOS format, these operations are compositional in CSP. For a valid translation into ACP, we will want the resulting translation to be compositional as well.

\section{Direct Translations}
Some of the basic operations of CSP have an identical equivalence in ACP, with the only difference being the syntax. These can be easily translated in the following table.

\begin{align*}
   \trans{STOP} &= \delta \\
   \trans{a \to P} &= a.\trans{P} \\
   \trans{P \backslash A} &= \partial_{A}{\trans{P}} \\
   % \trans{\mu p.P} &= \langle X \mid X = \tau.X \rangle
\end{align*}

\section{Trivial Translations}
\begin{itemize}
   \item \textbf{Divergence} is the process that diverges via infinite internal actions. It is defined by the following rule:
      \[\mathrm{div} \prightarrow{\tau} \mathrm{div}\]
      and then can be directly translated via recursion in ACP in the following rule:
      \[\trans{\mathrm{div}} = \langle X \mid X = \tau.X \rangle\] 
   \item \textbf{Renaming} is an operation that renames actions in processes according to a function. There is no equivalent function in plain $\mathrm{ACP}_{\tau}$, with the closest operation being $\tau_{I}(P)$ which abstracts actions in $I$ to internal actions.

      A proposed extension of ACP adds a Functional Renaming operator, as shown in [ON THE EXPRESSIVENESS OF ACP]. From this point forth, we will be using this extension, written as $ACP^{\tau}_{F}$. A clear translation is then shown to be
      \[\trans{f(P)} = f(\trans{P})\]
   \item \textbf{Internal Choice} is an operation that emulates a choice of actions that cannot be decided by the user. CSP in particular differs from ACP in that external choice and internal choice are separate operations, while in ACP, the alternative choice operator $+$ handles choice, albeit slightly differently. With the internal choice operator $\tau$, a translation for CSP Internal choice into ACP is easily written as
      \[\trans{P \sqcap Q} = \tau.\trans{P} + \tau.\trans{Q}\]
\end{itemize}

The above translations are all valid up to Strong Bisimilarity. The other operators are slightly harder to translate.

\section{Helper Operators for \texorpdfstring{$ACP_{F}^{\tau}$}{ACPtaur}}

Working in the language $ACP_{\tau}$ with the extension of Functional Renaming (written $ACP^{\tau}_{F}$), we start by defining some subsets of $A$ which we will use in our encodings.

\begin{dfn}[Subsets of A]{dfn:sets}{}
   The set $A\in \mathbb{T}$ is the set of all actions.
   \begin{itemize}
      \item $A_{0} \subseteq A$ is the set of actions that actually get used in processes
      \item $H_{0} = A - A_{0}$ is the set of working space operators, or any other action that doesn't get used
      \item $H_{1} = A_{0} \uplus \mathscr{H}$ is the set of actions, plus a set of working operators $\mathscr{H}$
   \end{itemize}

   In general, $A_{0} \subseteq H_{1} \subseteq A$.

   Note that the silent step is not defined in $A$, and we will define $A_{\tau}$ to be $A \cup \{\tau\}$
\end{dfn}

\newpage
\subsection{Triggering}
We define an operator $\Gamma(P)$ that emulates the Triggering operator of MEIJE [REFER]. For a trace $a.b.\cdots$ on a process $P$, the triggering operator can be represented as an operator that tags the first action of a process.

First, we define a function $f_{1}$ and communications for the operations $\mathtt{first}$ and $\mathtt{next}$.

\begin{multicols}{2}
   \begin{dfn}[F1]{dfn:f1}{}
      Define functions $f_{1}: A \to A$ where
      \begin{align*}
	 f_{1}(a_{\mathtt{first}}) &= a_{\mathtt{first}} \\
	 f_{1}(a_{\mathtt{next}}) &= a 
      \end{align*}
   \end{dfn}

   \begin{dfn-s}[Communications]{dfn:comm-triggering}{}
      Define communications where
      \begin{align*}
	 a | \mathtt{first} &= a_{\mathtt{first}}\\
	 a | \mathtt{next} &= a_{\mathtt{next}}
      \end{align*}
   \end{dfn-s}
\end{multicols}

We use the notation of $a^{\infty}$ as syntactic sugar to mean $\langle X \mid X = a.X \rangle$. We can now define $\Gamma(P)$ as such:

\begin{dfn}[Triggering in ACP]{dfn:acp-triggering}{}
	\[\Gamma(P) := \rho_{f_{1}}[\partial_{H_{1}}(p | | \mathtt{first}(\mathtt{next}^{\infty}))])\]
	is an operator that turns a trace of a process $P$, $a.b.c.\dots$ into the trace
	\[a_{\mathtt{first}}. b. c. \dots\]
\end{dfn}

This works in the following method:
\vspace{-5pt}
\begin{enumerate}
	\item Merge the process $P$ with the process $\mathtt{first}.\mathtt{next}.\mathtt{next}\dots$. Via Def \ref{dfn:comm-triggering}, this will produce a lattice of $P$ and $\mathtt{first}.(\mathtt{next}^{\infty})$, with communications on every square, but most importantly, a chain of communications going down the centre of the form.
		\begin{equation}\label{eq:fnn}
			a_{\mathtt{first}}. b_{\mathtt{next}} . c_{\mathtt{next}} \dots
		\end{equation}
	\item Restrict the actions in $H_{1}$. Since all the actions in $P, \mathtt{first}.(\mathtt{next}^{\infty}) \in H_{1}$ this effectively restricts both sides of the left merge, leaving only communications from the initial state. This leaves equation \ref{eq:fnn} as the only remaining trace.
	\item Apply $\rho_{f_{1}}$ to equation \ref{eq:fnn}. Via \ref{dfn:f1}, the final result is
		\begin{equation}\label{eq:gamma-result}
			a_{\mathtt{first}}. b . c \dots
		\end{equation}

		The process is now exactly as stated in Definition \ref{dfn:acp-triggering}.
\end{enumerate}
Note that since $\tau\not\in A$, $\partial_{H_{1}}$ will not restrict $\tau$, and additionally since $\tau$ does not communicate, Step 2 effectively becomes any amount of $\tau$ steps followed by the diagonal trace immediately following that. This results in cases $\Gamma(P)$ where $P = \tau.b.c\dots$ becoming the trace
\[\tau.b_{\mathtt{first}}.c.\dots\]
effectively skipping $\tau$'s, then acting the same as processes that don't start with a $\tau$.

\chapter{Conclusions}


\bibliographystyle{plainnat}
\bibliography{project}


\appendix

\chapter{First appendix}



\section{First section}

Any appendices, including any required ethics information, should be included
after the references.

Markers do not have to consider appendices. Make sure that your contributions
are made clear in the main body of the dissertation (within the page limit).

\end{document}
